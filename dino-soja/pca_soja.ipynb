{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6825e50e",
   "metadata": {},
   "source": [
    "# Computing the PCA of a Foreground Object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89fa7dd-f5c8-42b7-896c-8287d4e97105",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Let's start by loading some pre-requisites and checking the DINOv3 repository location:\n",
    "- `local` if `DINOV3_LOCATION` environment variable was set to work with a local version of DINOv3 repository;\n",
    "- `github` if the code should be loaded via torch hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd98e9-13eb-4e7a-a72b-27839dd463d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DINOv3 location set to /home/lades/computer_vision/wesley/dino-soja/dinov3\n",
      "Loading DINOv3 model dinov3_vitl16...\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import signal\n",
    "\n",
    "import random\n",
    "import tqdm # Progress bar\n",
    "from sklearn.metrics import pairwise_distances # Isso aqui é para calcular a distancia média entre os patches\n",
    "\n",
    "DINOV3_GITHUB_LOCATION = \"/home/lades/computer_vision/wesley/dino-soja/dinov3\"\n",
    "\n",
    "if os.getenv(\"DINOV3_LOCATION\") is not None:\n",
    "    DINOV3_LOCATION = os.getenv(\"DINOV3_LOCATION\")\n",
    "else:\n",
    "    DINOV3_LOCATION = DINOV3_GITHUB_LOCATION\n",
    "\n",
    "print(f\"DINOv3 location set to {DINOV3_LOCATION}\")\n",
    "\n",
    "# examples of available DINOv3 models:\n",
    "MODEL_DINOV3_VITS = \"dinov3_vits16\"\n",
    "MODEL_DINOV3_VITSP = \"dinov3_vits16plus\"\n",
    "MODEL_DINOV3_VITB = \"dinov3_vitb16\"\n",
    "MODEL_DINOV3_VITL = \"dinov3_vitl16\"\n",
    "MODEL_DINOV3_VITHP = \"dinov3_vith16plus\"\n",
    "MODEL_DINOV3_VIT7B = \"dinov3_vit7b16\"\n",
    "\n",
    "MODEL_NAME = MODEL_DINOV3_VITL\n",
    "\n",
    "print(f\"Loading DINOv3 model {MODEL_NAME}...\")\n",
    "\n",
    "model = torch.hub.load(\n",
    "    repo_or_dir=DINOV3_LOCATION,\n",
    "    model=MODEL_NAME,\n",
    "    source=\"local\",\n",
    "    weights=\"https://huggingface.co/MVRL/dinov3_vitl16_sat/resolve/main/dinov3_vitl16_pretrain_sat493m-eadcf0ff.pth\"\n",
    ")\n",
    "model.cuda()\n",
    "\n",
    "PATCH_SIZE = 16\n",
    "IMAGE_SIZE = 256\n",
    "\n",
    "SATELLITE_MEAN = (0.430, 0.411, 0.296)\n",
    "SATELLITE_STD = (0.213, 0.156, 0.143)\n",
    "\n",
    "MODEL_TO_NUM_LAYERS = {\n",
    "    MODEL_DINOV3_VITS: 12,\n",
    "    MODEL_DINOV3_VITSP: 12,\n",
    "    MODEL_DINOV3_VITB: 12,\n",
    "    MODEL_DINOV3_VITL: 24,\n",
    "    MODEL_DINOV3_VITHP: 32,\n",
    "    MODEL_DINOV3_VIT7B: 40,\n",
    "}\n",
    "\n",
    "n_layers = MODEL_TO_NUM_LAYERS[MODEL_NAME]\n",
    "    \n",
    "def load_image(path: str) -> Image:\n",
    "    return Image.open(path).convert(\"RGB\")\n",
    "\n",
    "# image resize transform to dimensions divisible by patch size\n",
    "def resize_transform(\n",
    "    mask_image: Image,\n",
    "    image_size: int = IMAGE_SIZE,\n",
    "    patch_size: int = PATCH_SIZE,\n",
    ") -> torch.Tensor:\n",
    "    w, h = mask_image.size\n",
    "    h_patches = int(image_size / patch_size)\n",
    "    w_patches = int((w * image_size) / (h * patch_size))\n",
    "    return TF.to_tensor(TF.resize(mask_image, (h_patches * patch_size, w_patches * patch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a069633a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using image /home/lades/computer_vision/wesley/dataset/daninhas_multiclasse/DATASET_CARURU/rgb/2025-09-17_TH134_06-05-2025_c_mask_14_8807_24073.jpg\n",
      "Using label /home/lades/computer_vision/wesley/dataset/daninhas_multiclasse/DATASET_CARURU/labels/2025-09-17_TH134_06-05-2025_c_mask_14_8807_24073.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0,   1, 255], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obter imagem aleatória do dataset\n",
    "dataset_path = \"/home/lades/computer_vision/wesley/dataset/daninhas_multiclasse/DATASET_CARURU/rgb/\"\n",
    "image_uri = f\"{dataset_path}{random.choice(os.listdir(dataset_path))}\"\n",
    "\n",
    "print(f\"Using image {image_uri}\")\n",
    "\n",
    "# Obtém o respectivo label\n",
    "label_uri = image_uri.replace(\"rgb\", \"labels\").replace(\".jpg\", \".png\")\n",
    "label = np.array(Image.open(label_uri))\n",
    "\n",
    "print(f\"Using label {label_uri}\")\n",
    "np.unique(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39b22b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_pca(label, image_uri): \n",
    "    # Cria a máscara de foreground (tudo que estiver no fundo preto que seja diferente de branco)\n",
    "    label_mask = (label == 1).astype(np.float32)\n",
    "    label_mask = signal.convolve2d(label_mask, np.ones((PATCH_SIZE, PATCH_SIZE)), mode='valid')[::PATCH_SIZE, ::PATCH_SIZE]\n",
    "    fg_score_mf = torch.from_numpy(label_mask > 0.5)\n",
    "\n",
    "    image = load_image(image_uri)\n",
    "    image_resized = resize_transform(image)\n",
    "    image_resized_norm = TF.normalize(image_resized, mean=SATELLITE_MEAN, std=SATELLITE_STD)\n",
    "\n",
    "    h_patches, w_patches = image_resized_norm.shape[1] // PATCH_SIZE, image_resized_norm.shape[2] // PATCH_SIZE\n",
    "    print(f\"Image size: {image_resized_norm.shape}, patches: {h_patches}x{w_patches}\")\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float32):\n",
    "            feats = model.get_intermediate_layers(image_resized_norm.unsqueeze(0).cuda(), n=range(n_layers), reshape=True, norm=True)\n",
    "            x = feats[-1].squeeze().detach().cpu()\n",
    "            dim = x.shape[0]\n",
    "            x = x.view(dim, -1).permute(1, 0)\n",
    "            \n",
    "    fg_patches = x\n",
    "\n",
    "    pca = PCA(n_components=3, whiten=True)\n",
    "    pca.fit(fg_patches)\n",
    "\n",
    "    # apply the PCA, and then reshape\n",
    "    projected_image = torch.from_numpy(pca.transform(x.numpy())).view(h_patches, w_patches, 3)\n",
    "\n",
    "    # multiply by 2.0 and pass through a sigmoid to get vibrant colors \n",
    "    projected_image = torch.nn.functional.sigmoid(projected_image.mul(2.0)).permute(2, 0, 1)\n",
    "\n",
    "    # mask the background using the fg_score_mf\n",
    "    projected_foreground_image = projected_image * (fg_score_mf.unsqueeze(0) > 0.5)\n",
    "    \n",
    "    projected_background_image = projected_image * (fg_score_mf.unsqueeze(0) <= 0.5)\n",
    "\n",
    "    return projected_image, projected_foreground_image, projected_background_image\n",
    "\n",
    "def plotar_imagens(image_uri, projected_image, projected_foreground_image, label_mask, label_uri):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 5, 1)\n",
    "    plt.imshow(np.array(Image.open(image_uri)))\n",
    "    plt.title(\"Imagem original\")\n",
    "    plt.subplot(1, 5, 2)\n",
    "    plt.imshow(projected_image.permute(1, 2, 0))\n",
    "    plt.title(\"PCA da imagem projetada\")\n",
    "    plt.subplot(1, 5, 3)\n",
    "    plt.imshow(projected_foreground_image.permute(1, 2, 0))\n",
    "    plt.title(\"PCA da imagem projetada + mask\")\n",
    "    plt.subplot(1, 5, 4)\n",
    "    plt.imshow(np.array(Image.fromarray(label_mask)))\n",
    "    plt.title(\"PCA da mask label (GT)\")\n",
    "    plt.subplot(1, 5, 5)\n",
    "    plt.imshow(Image.open(label_uri))\n",
    "    plt.title(\"Label (GT)\")\n",
    "    plt.show()\n",
    "\n",
    "    # Exibir label_mask com os valores de cada bloquinho\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(label_mask)\n",
    "    for i in range(label_mask.shape[0]):\n",
    "        for j in range(label_mask.shape[1]):\n",
    "            plt.text(j, i, f\"{label_mask[i, j]:.1f}\", ha='center', va='center', color='white')\n",
    "    plt.show()\n",
    "\n",
    "    # Exibir projected_image com os valores de cada bloquinho\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(projected_image.permute(1, 2, 0))\n",
    "    for i in range(projected_image.shape[1]):\n",
    "        for j in range(projected_image.shape[2]):\n",
    "            plt.text(j, i, f\"{projected_image[0, i, j]:.1f}\", ha='center', va='center', color='white')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1936f236",
   "metadata": {},
   "source": [
    "### Experimento\n",
    "Neste experimento, irei considerar o mask label da respectiva imagem, para separar os patches do PCA da imagem que estiverem dentro da mask label da imagem. Isso sera o foreground e o restante, background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82cc18e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_tensores(label, image_uri):\n",
    "    image = load_image(image_uri)\n",
    "    image_resized = resize_transform(image)\n",
    "    image_resized_norm = TF.normalize(image_resized, mean=SATELLITE_MEAN, std=SATELLITE_STD)\n",
    "\n",
    "    label_mask = (label == 1).astype(np.float32)\n",
    "    label_mask = signal.convolve2d(label_mask, np.ones((PATCH_SIZE, PATCH_SIZE)), mode='valid')[::PATCH_SIZE, ::PATCH_SIZE]\n",
    "    fg_score_mf = torch.from_numpy(label_mask > 0.5)\n",
    "\n",
    "    h_patches, w_patches = image_resized_norm.shape[1] // PATCH_SIZE, image_resized_norm.shape[2] // PATCH_SIZE\n",
    "    #print(f\"Image size: {image_resized_norm.shape}, patches: {h_patches}x{w_patches}\")\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float32):\n",
    "            feats = model.get_intermediate_layers(image_resized_norm.unsqueeze(0).cuda(), n=range(n_layers), reshape=True, norm=True)\n",
    "            x = feats[-1].squeeze().detach().cpu()\n",
    "            dim = x.shape[0]\n",
    "            x = x.view(dim, -1).permute(1, 0)\n",
    "            \n",
    "    x.shape, fg_score_mf.shape\n",
    "\n",
    "    # Dividir x em foreground e background, considerando a label_mask\n",
    "    foreground_x = x[fg_score_mf.view(-1) > 0.5]\n",
    "    background_x = x[fg_score_mf.view(-1) <= 0.5]\n",
    "\n",
    "    #print(f'Foreground: {foreground_x.shape}, Background: {background_x.shape}')\n",
    "\n",
    "    return x, foreground_x, background_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4894d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupar_tensores(dataset_path): # dataset_path deve ser o path do dataset (ex: .../DATASET_CARURU/)\n",
    "    dataset_path_rgb = f\"{dataset_path}/rgb/\"\n",
    "    dataset_path_label = f\"{dataset_path}/labels/\" # Extensão png\n",
    "    \n",
    "    lista_imagens = [f\"{dataset_path_rgb}{file}\" for file in os.listdir(dataset_path_rgb) if file.endswith('.jpg')]\n",
    "    lista_labels = [f\"{dataset_path_label}{file}\" for file in os.listdir(dataset_path_label) if file.endswith('.png')]\n",
    "    \n",
    "    lista_imagens.sort()\n",
    "    lista_labels.sort()\n",
    "\n",
    "    print(f\"Foram encontrados {len(lista_imagens)} imagens e {len(lista_labels)} labels.\")\n",
    "\n",
    "    x_foreground = []\n",
    "    x_background = []\n",
    "\n",
    "    # Iterar sobre as imagens utilizando tqdm para mostrar o progresso\n",
    "    for image_uri, label_uri in tqdm.tqdm(zip(lista_imagens, lista_labels), total=len(lista_imagens)):\n",
    "        label = np.array(Image.open(label_uri))\n",
    "        x, foreground, background = extrair_tensores(label, image_uri)\n",
    "        x_foreground.append(foreground)\n",
    "        x_background.append(background)\n",
    "\n",
    "    all_foreground = torch.cat(x_foreground, dim=0)\n",
    "    all_background = torch.cat(x_background, dim=0)\n",
    "    \n",
    "    print(f'Total Foreground: {all_foreground.shape}, Total Background: {all_background.shape}')\n",
    "    \n",
    "    return all_foreground, all_background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e06f7534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CARURU', 'DATASET_CARURU', 'CAR'),\n",
       " ('GRAMINEA_PORTE_ALTO', 'DATASET_GRAMINEA_PORTE_ALTO', 'GPA'),\n",
       " ('GRAMINEA_PORTE_BAIXO', 'DATASET_GRAMINEA_PORTE_BAIXO', 'GPB'),\n",
       " ('MAMONA', 'DATASET_MAMONA', 'MAM'),\n",
       " ('OUTRAS_FOLHAS_LARGAS', 'DATASET_OUTRAS_FOLHAS_LARGAS', 'OFL'),\n",
       " ('TREPADEIRA', 'DATASET_TREPADEIRA', 'TRE')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"/home/lades/computer_vision/wesley/dataset/daninhas_multiclasse/\"\n",
    "\n",
    "# Obter os nomes das classes, pelo sufixo DATASET_\n",
    "dir_classes = [d for d in os.listdir(dataset_path) if d.startswith(\"DATASET_\")]\n",
    "\n",
    "classes = []\n",
    "for dir_class in dir_classes:\n",
    "    class_name = dir_class.split(\"DATASET_\")[-1]\n",
    "    # nickname sera as 3 primeiras letras (se a classe tiver somente uma palavra); ou as iniciais das palavras (se tiver mais de uma palavra)\n",
    "    if \"_\" in class_name:\n",
    "        nickname = \"\".join([word[0] for word in class_name.split(\"_\")]).upper()\n",
    "    else:\n",
    "        nickname = class_name[:3].upper()\n",
    "    classes.append((class_name, dir_class, nickname))\n",
    "\n",
    "classes.sort()\n",
    "\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36f0d57",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel deu pane ao executar o código na célula atual ou em uma célula anterior. \n",
      "\u001b[1;31mAnalise o código nas células para identificar uma possível causa da pane. \n",
      "\u001b[1;31mClique <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqui</a> para obter mais informações. \n",
      "\u001b[1;31mConsulte Jupyter <a href='command:jupyter.viewOutput'>log</a> para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "def calcular_distancias_e_desvio_padrao(all_x_foreground, all_x_background, \n",
    "                                 max_samples_fg=5000, max_samples_bg=10000):\n",
    "    \"\"\"\n",
    "    Calcula distâncias usando amostragem para economizar memória\n",
    "    \"\"\"\n",
    "    print(f\"Original - FG: {all_x_foreground.shape[0]:,}, BG: {all_x_background.shape[0]:,}\")\n",
    "    \n",
    "    if all_x_foreground.shape[0] > max_samples_fg:\n",
    "        # Amostrar foreground\n",
    "        indices_fg = torch.randperm(all_x_foreground.shape[0])[:max_samples_fg]\n",
    "        fg_sample = all_x_foreground[indices_fg]\n",
    "        #print(f\"Amostrando foreground: {max_samples_fg:,} patches\")\n",
    "    else:\n",
    "        fg_sample = all_x_foreground\n",
    "        \n",
    "    if all_x_background.shape[0] > max_samples_bg:\n",
    "        # Amostrar background\n",
    "        indices_bg = torch.randperm(all_x_background.shape[0])[:max_samples_bg]\n",
    "        bg_sample = all_x_background[indices_bg]\n",
    "        #print(f\"Amostrando background: {max_samples_bg:,} patches\")\n",
    "    else:\n",
    "        bg_sample = all_x_background\n",
    "    \n",
    "    print(f\"Calculando distâncias: {fg_sample.shape[0]:,} x {fg_sample.shape[0]:,} (intra)\")\n",
    "    print(f\"Calculando distâncias: {fg_sample.shape[0]:,} x {bg_sample.shape[0]:,} (inter)\")\n",
    "    \n",
    "    # Calcular distâncias nas amostras\n",
    "    mean_dist_intra = pairwise_distances(fg_sample).mean()\n",
    "    mean_dist_inter = pairwise_distances(fg_sample, bg_sample).mean()\n",
    "    std_intra = pairwise_distances(fg_sample).std()\n",
    "    std_inter = pairwise_distances(fg_sample, bg_sample).std()\n",
    "\n",
    "    return mean_dist_intra, mean_dist_inter, std_intra, std_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dd6fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances_torch(x, y=None):\n",
    "    \"\"\"\n",
    "    Uma função wrapper que usa as funções de distância nativas do PyTorch.\n",
    "    Ela roda na GPU se os tensores de entrada estiverem na GPU.\n",
    "    \"\"\"\n",
    "    if y is None:\n",
    "        # torch.pdist calcula a distância par-a-par dentro de um único tensor\n",
    "        return torch.pdist(x)\n",
    "    else:\n",
    "        # torch.cdist calcula a distância entre cada par de vetores de dois tensores\n",
    "        return torch.cdist(x, y)\n",
    "\n",
    "def calcular_distancias_otimizado(all_x_foreground, all_x_background, batch_size=256):\n",
    "    \"\"\"\n",
    "    Calcula a média e o desvio padrão das distâncias usando processamento em lotes\n",
    "    para economizar memória, utilizando 100% dos dados.\n",
    "    \"\"\"\n",
    "    device = all_x_foreground.device # Usa o mesmo dispositivo (CPU ou GPU) dos tensores\n",
    "    print(f\"Iniciando cálculo otimizado com batch size: {batch_size}\")\n",
    "    print(f\"Usando dispositivo: {device}\")\n",
    "    \n",
    "    # --- Cálculo INTRA-CLASSE (foreground vs foreground) ---\n",
    "    print(f\"Calculando distâncias intra-classe para {all_x_foreground.shape[0]:,} vetores...\")\n",
    "    count_intra = 0\n",
    "    mean_intra = torch.tensor(0.0, device=device)\n",
    "    M2_intra = torch.tensor(0.0, device=device)\n",
    "\n",
    "    # Itera sobre os dados em lotes com tqdm\n",
    "    for i in tqdm.tqdm(range(0, all_x_foreground.shape[0], batch_size), desc=\"Intra-classe\"):\n",
    "        batch_fg = all_x_foreground[i:i + batch_size]\n",
    "        \n",
    "        # Calcula distâncias apenas deste lote contra todos os outros\n",
    "        dist_batch = pairwise_distances_torch(batch_fg, all_x_foreground)\n",
    "        \n",
    "        # Algoritmo de Welford para média e variância online\n",
    "        for d in dist_batch.flatten(): # Itera sobre cada distância calculada\n",
    "            count_intra += 1\n",
    "            delta = d - mean_intra\n",
    "            mean_intra += delta / count_intra\n",
    "            delta2 = d - mean_intra\n",
    "            M2_intra += delta * delta2\n",
    "\n",
    "    std_intra = torch.sqrt(M2_intra / count_intra) if count_intra > 0 else torch.tensor(0.0)\n",
    "    \n",
    "    # --- Cálculo INTER-CLASSE (foreground vs background) ---\n",
    "    print(f\"Calculando distâncias inter-classe para {all_x_foreground.shape[0]:,} vs {all_x_background.shape[0]:,} vetores...\")\n",
    "    count_inter = 0\n",
    "    mean_inter = torch.tensor(0.0, device=device)\n",
    "    M2_inter = torch.tensor(0.0, device=device)\n",
    "\n",
    "    for i in tqdm.tqdm(range(0, all_x_foreground.shape[0], batch_size), desc=\"Inter-classe\"):\n",
    "        batch_fg = all_x_foreground[i:i + batch_size]\n",
    "        \n",
    "        # Calcula distâncias apenas deste lote contra todo o background\n",
    "        dist_batch = pairwise_distances(batch_fg, all_x_background)\n",
    "        \n",
    "        # Algoritmo de Welford\n",
    "        for d in dist_batch.flatten():\n",
    "            count_inter += 1\n",
    "            delta = d - mean_inter\n",
    "            mean_inter += delta / count_inter\n",
    "            delta2 = d - mean_inter\n",
    "            M2_inter += delta * delta2\n",
    "            \n",
    "    std_inter = torch.sqrt(M2_inter / count_inter) if count_inter > 0 else torch.tensor(0.0)\n",
    "\n",
    "    return mean_intra.item(), mean_inter.item(), std_intra.item(), std_inter.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a91724c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_stats(mean_A, M2_A, count_A, mean_B, M2_B, count_B):\n",
    "    \"\"\"\n",
    "    Combina estatísticas de dois conjuntos. A entrada precisa ser dois tensores com média e contagem.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Iteração inicial\n",
    "    if count_A == 0:\n",
    "        return mean_B, M2_B, count_B\n",
    "    \n",
    "    if count_B == 0:\n",
    "        return mean_A, M2_A, count_A\n",
    "    \n",
    "    count_total = count_A + count_B\n",
    "    \n",
    "    delta = mean_B - mean_A # Diferença\n",
    "    \n",
    "    # Média ponderada. N precisa verificar se é maior do que zero, porque já foi verificado antes\n",
    "    mean_total = (mean_A * count_A + mean_B * count_B) / count_total\n",
    "    \n",
    "    # Atualiza M2 usando a fórmula de combinação\n",
    "    M2_total = M2_A + M2_B + delta * delta * (count_A * count_B) / count_total\n",
    "    \n",
    "    return mean_total, M2_total, count_total\n",
    "\n",
    "def calcular_distancias_otimizado2(all_x_foreground, all_x_background, batch_size=256):\n",
    "    \"\"\"\n",
    "    Esta versão irá calcular as distancias em lotes, utilizando a VRAM (24GB). Como não conseguiremos carregar tudo na VRAM, faremos em lotes.\n",
    "    A ideia é utilizar a combine_stats para ir acumulando as médias e desvios padrão.\n",
    "    Essa versão calcula as distancias na VRAM.\n",
    "    \"\"\"\n",
    "    device = all_x_foreground.device # Usa o mesmo dispositivo (CPU ou GPU) dos tensores\n",
    "    print(f\"Iniciando cálculo otimizado com batch size: {batch_size}\")\n",
    "    print(f\"Usando dispositivo: {device}\")\n",
    "    \n",
    "    # --- Cálculo INTRA-CLASSE (foreground vs foreground) ---\n",
    "    print(f\"Calculando distâncias intra-classe para {all_x_foreground.shape[0]:,} vetores...\")\n",
    "    mean_intra = torch.tensor(0.0, device=device, dtype=all_x_foreground.dtype)\n",
    "    M2_intra = torch.tensor(0.0, device=device, dtype=all_x_foreground.dtype)\n",
    "    count_intra = torch.tensor(0, device=device, dtype=torch.int64)\n",
    "    \n",
    "    # Itera sobre os dados em lotes com tqdm\n",
    "    for i in tqdm.tqdm(range(0, all_x_foreground.shape[0], batch_size), desc=\"Intra-classe\"):\n",
    "        batch_fg = all_x_foreground[i:i + batch_size]\n",
    "                        \n",
    "        # Calcula distâncias apenas deste lote contra todos os outros\n",
    "        dist_batch = pairwise_distances_torch(batch_fg, all_x_foreground)\n",
    "        \n",
    "        batch_count = torch.tensor(dist_batch.numel(), device=device, dtype=torch.int64)\n",
    "        \n",
    "        if batch_count == 0:\n",
    "            continue\n",
    "\n",
    "        # Calcula estatísticas do lote atual\n",
    "        batch_mean = torch.mean(dist_batch)\n",
    "        \n",
    "        torch.sub(dist_batch, batch_mean, out=dist_batch)\n",
    "        torch.pow(dist_batch, 2, out=dist_batch)\n",
    "        batch_M2 = torch.sum(dist_batch)\n",
    "        \n",
    "        # Combina as estatísticas do lote com as acumuladas\n",
    "        mean_intra, M2_intra, count_intra = combine_stats(mean_intra, M2_intra, count_intra, batch_mean, batch_M2, batch_count)\n",
    "        \n",
    "        del dist_batch, batch_mean, batch_M2, batch_count\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    std_intra = torch.sqrt(M2_intra / count_intra) if count_intra > 0 else torch.tensor(0.0, device=device, dtype=all_x_foreground.dtype)\n",
    "\n",
    "    # --- Cálculo INTER-CLASSE (foreground vs background) ---\n",
    "    print(f\"Calculando distâncias inter-classe para {all_x_foreground.shape[0]:,} vs {all_x_background.shape[0]:,} vetores...\")\n",
    "    mean_inter = torch.tensor(0.0, device=device, dtype=all_x_foreground.dtype)\n",
    "    M2_inter = torch.tensor(0.0, device=device, dtype=all_x_foreground.dtype)\n",
    "    count_inter = torch.tensor(0, device=device, dtype=torch.int64)\n",
    "    \n",
    "    for i in tqdm.tqdm(range(0, all_x_foreground.shape[0], batch_size), desc=\"Inter-classe\"):\n",
    "        batch_fg = all_x_foreground[i:i + batch_size]\n",
    "                        \n",
    "        # Calcula distâncias apenas deste lote contra todo o background\n",
    "        dist_batch = pairwise_distances_torch(batch_fg, all_x_background)\n",
    "        \n",
    "        batch_count = torch.tensor(dist_batch.numel(), device=device, dtype=torch.int64)\n",
    "        \n",
    "        if batch_count == 0:\n",
    "            continue\n",
    "\n",
    "        # Calcula estatísticas do lote atual\n",
    "        batch_mean = torch.mean(dist_batch)\n",
    "        \n",
    "        torch.sub(dist_batch, batch_mean, out=dist_batch)\n",
    "        torch.pow(dist_batch, 2, out=dist_batch)\n",
    "        batch_M2 = torch.sum(dist_batch)\n",
    "        #batch_M2 = torch.sum((dist_batch - batch_mean) ** 2)\n",
    "                \n",
    "        # Combina as estatísticas do lote com as acumuladas\n",
    "        mean_inter, M2_inter, count_inter = combine_stats(mean_inter, M2_inter, count_inter, batch_mean, batch_M2, batch_count)\n",
    "        \n",
    "        del dist_batch, batch_mean, batch_M2, batch_count\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    std_inter = torch.sqrt(M2_inter / count_inter) if count_inter > 0 else torch.tensor(0.0, device=device, dtype=all_x_foreground.dtype)\n",
    "    \n",
    "    return mean_intra.item(), mean_inter.item(), std_intra.item(), std_inter.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5795dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando classe CARURU – CAR...\n",
      "Foram encontrados 97 imagens e 97 labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:11<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Foreground: torch.Size([5205, 1024]), Total Background: torch.Size([19627, 1024])\n",
      "Iniciando cálculo otimizado com batch size: 256\n",
      "Calculando distâncias intra-classe para 5,205 vetores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intra-classe: 100%|██████████| 21/21 [12:12<00:00, 34.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando distâncias inter-classe para 5,205 vs 19,627 vetores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inter-classe: 100%|██████████| 21/21 [51:38<00:00, 147.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distância média CAR_CAR: 5.084751605987549, CAR_not_CAR: 5.579956531524658\n",
      "Desvio padrão CAR_CAR: 0.6484483480453491, CAR_not_CAR: 0.5424074530601501\n",
      "Processando classe GRAMINEA_PORTE_ALTO – GPA...\n",
      "Foram encontrados 2726 imagens e 2726 labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2726/2726 [03:29<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Foreground: torch.Size([27369, 1024]), Total Background: torch.Size([670487, 1024])\n",
      "Iniciando cálculo otimizado com batch size: 256\n",
      "Calculando distâncias intra-classe para 27,369 vetores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intra-classe: 100%|██████████| 107/107 [3:47:57<00:00, 127.82s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando distâncias inter-classe para 27,369 vs 670,487 vetores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inter-classe:  23%|██▎       | 25/107 [35:29:54<115:13:03, 5058.33s/it]"
     ]
    }
   ],
   "source": [
    "# Iterar sobre as classes e criar um array unico. Inicialmente conterá todas as all_foreground, all_background, mean_dist_classe_classe e mean_dist_classe_not_classe por classe\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, (class_name, dir_class, nickname) in enumerate(classes):\n",
    "    print(f\"Processando classe {class_name} – {nickname}...\")\n",
    "    all_x_foreground, all_x_background = agrupar_tensores(f\"{dataset_path}{dir_class}\")\n",
    "    #mean_dist_classe_classe = pairwise_distances(all_x_foreground).mean()\n",
    "    #mean_dist_classe_not_classe = pairwise_distances(all_x_foreground, all_x_background).mean()\n",
    "    #mean_dist_classe_classe, mean_dist_classe_not_classe, std_classe_classe, std_classe_not_classe = calcular_distancias_e_desvio_padrao(all_x_foreground, all_x_background, max_samples_fg=int(0.5*all_x_foreground.shape[0]), max_samples_bg=int(0.5*all_x_background.shape[0]))\n",
    "    mean_dist_classe_classe, mean_dist_classe_not_classe, std_classe_classe, std_classe_not_classe = calcular_distancias_otimizado(all_x_foreground, all_x_background, batch_size=256)\n",
    "\n",
    "    results.append({\n",
    "        \"class\": nickname,\n",
    "        \"all_foreground\": all_x_foreground,\n",
    "        \"all_background\": all_x_background,\n",
    "        \"mean_dist_classe_classe\": mean_dist_classe_classe,\n",
    "        \"mean_dist_classe_not_classe\": mean_dist_classe_not_classe,\n",
    "        \"std_classe_classe\": std_classe_classe,\n",
    "        \"std_classe_not_classe\": std_classe_not_classe\n",
    "    })\n",
    "    print(f\"Distância média {nickname}_{nickname}: {mean_dist_classe_classe}, {nickname}_not_{nickname}: {mean_dist_classe_not_classe}\")\n",
    "    print(f\"Desvio padrão {nickname}_{nickname}: {std_classe_classe}, {nickname}_not_{nickname}: {std_classe_not_classe}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "827e6685",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0327a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando classe CARURU – CAR...\n",
      "Foram encontrados 97 imagens e 97 labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:05<00:00, 16.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Foreground: torch.Size([5205, 1024]), Total Background: torch.Size([19627, 1024])\n",
      "Iniciando cálculo otimizado com batch size: 4096\n",
      "Usando dispositivo: cpu\n",
      "Calculando distâncias intra-classe para 5,205 vetores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intra-classe: 100%|██████████| 2/2 [00:00<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando distâncias inter-classe para 5,205 vs 19,627 vetores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inter-classe: 100%|██████████| 2/2 [00:00<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distância média CAR_CAR: 5.212090492248535, CAR_not_CAR: 5.625874042510986\n",
      "Desvio padrão CAR_CAR: 0.6607735753059387, CAR_not_CAR: 0.6303556561470032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class_name, dir_class, nickname = classes[0]\n",
    "\n",
    "print(f\"Processando classe {class_name} – {nickname}...\")\n",
    "all_x_foreground, all_x_background = agrupar_tensores(f\"{dataset_path}{dir_class}\")\n",
    "mean_dist_classe_classe, mean_dist_classe_not_classe, std_classe_classe, std_classe_not_classe = calcular_distancias_otimizado2(all_x_foreground, all_x_background, batch_size=4096)\n",
    "\n",
    "print(f\"Distância média {nickname}_{nickname}: {mean_dist_classe_classe}, {nickname}_not_{nickname}: {mean_dist_classe_not_classe}\")\n",
    "print(f\"Desvio padrão {nickname}_{nickname}: {std_classe_classe}, {nickname}_not_{nickname}: {std_classe_not_classe}\")\n",
    "\n",
    "results.append({\n",
    "    \"class\": nickname,\n",
    "    #\"all_foreground\": all_x_foreground,\n",
    "    #\"all_background\": all_x_background,\n",
    "    \"mean_dist_classe_classe\": mean_dist_classe_classe,\n",
    "    \"mean_dist_classe_not_classe\": mean_dist_classe_not_classe,\n",
    "    \"std_classe_classe\": std_classe_classe,\n",
    "    \"std_classe_not_classe\": std_classe_not_classe\n",
    "})\n",
    "\n",
    "del all_x_foreground, all_x_background\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Salvar resultados em um arquivo txt\n",
    "with open(\"pca_soja_results-2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf6a59f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class': 'CAR',\n",
       "  'mean_dist_classe_classe': 5.212090492248535,\n",
       "  'mean_dist_classe_not_classe': 5.625874042510986,\n",
       "  'std_classe_classe': 0.6607735753059387,\n",
       "  'std_classe_not_classe': 0.6303556561470032}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9801a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cde6b940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando classe GRAMINEA_PORTE_ALTO – GPA...\n",
      "Foram encontrados 2726 imagens e 2726 labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2726 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2726/2726 [02:38<00:00, 17.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Foreground: torch.Size([27369, 1024]), Total Background: torch.Size([670487, 1024])\n",
      "Iniciando cálculo otimizado com batch size: 4096\n",
      "Usando dispositivo: cuda:0\n",
      "Calculando distâncias intra-classe para 27,369 vetores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intra-classe: 100%|██████████| 7/7 [00:00<00:00, 43.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando distâncias inter-classe para 27,369 vs 670,487 vetores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inter-classe: 100%|██████████| 7/7 [00:03<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distância média GPA_GPA: 6.254695892333984, GPA_not_GPA: 6.467916488647461\n",
      "Desvio padrão GPA_GPA: 1.230429768562317, GPA_not_GPA: 1.2287890911102295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class_name, dir_class, nickname = classes[1]\n",
    "\n",
    "print(f\"Processando classe {class_name} – {nickname}...\")\n",
    "all_x_foreground, all_x_background = agrupar_tensores(f\"{dataset_path}{dir_class}\")\n",
    "\n",
    "mean_dist_classe_classe, mean_dist_classe_not_classe, std_classe_classe, std_classe_not_classe = calcular_distancias_otimizado2(all_x_foreground.to(device), all_x_background.to(device), batch_size=4096)\n",
    "\n",
    "print(f\"Distância média {nickname}_{nickname}: {mean_dist_classe_classe}, {nickname}_not_{nickname}: {mean_dist_classe_not_classe}\")\n",
    "print(f\"Desvio padrão {nickname}_{nickname}: {std_classe_classe}, {nickname}_not_{nickname}: {std_classe_not_classe}\")\n",
    "\n",
    "results.append({\n",
    "    \"class\": nickname,\n",
    "    #\"all_foreground\": all_x_foreground,\n",
    "    #\"all_background\": all_x_background,\n",
    "    \"mean_dist_classe_classe\": mean_dist_classe_classe,\n",
    "    \"mean_dist_classe_not_classe\": mean_dist_classe_not_classe,\n",
    "    \"std_classe_classe\": std_classe_classe,\n",
    "    \"std_classe_not_classe\": std_classe_not_classe\n",
    "})\n",
    "\n",
    "del all_x_foreground, all_x_background\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Salvar resultados em um arquivo txt\n",
    "with open(\"pca_soja_results-2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f1a40a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando classe GRAMINEA_PORTE_BAIXO – GPB...\n",
      "Foram encontrados 1747 imagens e 1747 labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1747/1747 [01:40<00:00, 17.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Foreground: torch.Size([15705, 1024]), Total Background: torch.Size([431527, 1024])\n",
      "Iniciando cálculo otimizado com batch size: 4096\n",
      "Usando dispositivo: cuda:0\n",
      "Calculando distâncias intra-classe para 15,705 vetores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intra-classe: 100%|██████████| 4/4 [00:00<00:00, 79.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando distâncias inter-classe para 15,705 vs 431,527 vetores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inter-classe: 100%|██████████| 4/4 [00:01<00:00,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distância média GPB_GPB: 5.876298904418945, GPB_not_GPB: 6.169379234313965\n",
      "Desvio padrão GPB_GPB: 0.6613664627075195, GPB_not_GPB: 0.5903793573379517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class_name, dir_class, nickname = classes[2]\n",
    "\n",
    "print(f\"Processando classe {class_name} – {nickname}...\")\n",
    "all_x_foreground, all_x_background = agrupar_tensores(f\"{dataset_path}{dir_class}\")\n",
    "\n",
    "mean_dist_classe_classe, mean_dist_classe_not_classe, std_classe_classe, std_classe_not_classe = calcular_distancias_otimizado2(all_x_foreground.to(device), all_x_background.to(device), batch_size=4096)\n",
    "\n",
    "print(f\"Distância média {nickname}_{nickname}: {mean_dist_classe_classe}, {nickname}_not_{nickname}: {mean_dist_classe_not_classe}\")\n",
    "print(f\"Desvio padrão {nickname}_{nickname}: {std_classe_classe}, {nickname}_not_{nickname}: {std_classe_not_classe}\")\n",
    "\n",
    "results.append({\n",
    "    \"class\": nickname,\n",
    "    #\"all_foreground\": all_x_foreground,\n",
    "    #\"all_background\": all_x_background,\n",
    "    \"mean_dist_classe_classe\": mean_dist_classe_classe,\n",
    "    \"mean_dist_classe_not_classe\": mean_dist_classe_not_classe,\n",
    "    \"std_classe_classe\": std_classe_classe,\n",
    "    \"std_classe_not_classe\": std_classe_not_classe\n",
    "})\n",
    "\n",
    "del all_x_foreground, all_x_background\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Salvar resultados em um arquivo txt\n",
    "with open(\"pca_soja_results-2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd96ceee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando classe MAMONA – MAM...\n",
      "Foram encontrados 1103 imagens e 1103 labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1103/1103 [01:04<00:00, 16.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Foreground: torch.Size([10524, 1024]), Total Background: torch.Size([271844, 1024])\n",
      "Iniciando cálculo otimizado com batch size: 4096\n",
      "Usando dispositivo: cuda:0\n",
      "Calculando distâncias intra-classe para 10,524 vetores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intra-classe: 100%|██████████| 3/3 [00:00<00:00, 118.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando distâncias inter-classe para 10,524 vs 271,844 vetores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inter-classe: 100%|██████████| 3/3 [00:00<00:00,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distância média MAM_MAM: 7.107694149017334, MAM_not_MAM: 7.039205551147461\n",
      "Desvio padrão MAM_MAM: 4.076447486877441, MAM_not_MAM: 3.2064595222473145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class_name, dir_class, nickname = classes[3]\n",
    "\n",
    "print(f\"Processando classe {class_name} – {nickname}...\")\n",
    "all_x_foreground, all_x_background = agrupar_tensores(f\"{dataset_path}{dir_class}\")\n",
    "\n",
    "mean_dist_classe_classe, mean_dist_classe_not_classe, std_classe_classe, std_classe_not_classe = calcular_distancias_otimizado2(all_x_foreground.to(device), all_x_background.to(device), batch_size=4096)\n",
    "\n",
    "print(f\"Distância média {nickname}_{nickname}: {mean_dist_classe_classe}, {nickname}_not_{nickname}: {mean_dist_classe_not_classe}\")\n",
    "print(f\"Desvio padrão {nickname}_{nickname}: {std_classe_classe}, {nickname}_not_{nickname}: {std_classe_not_classe}\")\n",
    "\n",
    "results.append({\n",
    "    \"class\": nickname,\n",
    "    #\"all_foreground\": all_x_foreground,\n",
    "    #\"all_background\": all_x_background,\n",
    "    \"mean_dist_classe_classe\": mean_dist_classe_classe,\n",
    "    \"mean_dist_classe_not_classe\": mean_dist_classe_not_classe,\n",
    "    \"std_classe_classe\": std_classe_classe,\n",
    "    \"std_classe_not_classe\": std_classe_not_classe\n",
    "})\n",
    "\n",
    "del all_x_foreground, all_x_background\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Salvar resultados em um arquivo txt\n",
    "with open(\"pca_soja_results-2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f6253a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando classe OUTRAS_FOLHAS_LARGAS – OFL...\n",
      "Foram encontrados 2999 imagens e 2999 labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2999/2999 [02:54<00:00, 17.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Foreground: torch.Size([28817, 1024]), Total Background: torch.Size([738927, 1024])\n",
      "Iniciando cálculo otimizado com batch size: 4096\n",
      "Usando dispositivo: cuda:0\n",
      "Calculando distâncias intra-classe para 28,817 vetores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intra-classe: 100%|██████████| 8/8 [00:00<00:00, 53.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando distâncias inter-classe para 28,817 vs 738,927 vetores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inter-classe: 100%|██████████| 8/8 [00:04<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distância média OFL_OFL: 6.133740425109863, OFL_not_OFL: 6.291485786437988\n",
      "Desvio padrão OFL_OFL: 1.0084186792373657, OFL_not_OFL: 0.8828402757644653\n"
     ]
    }
   ],
   "source": [
    "class_name, dir_class, nickname = classes[4]\n",
    "\n",
    "print(f\"Processando classe {class_name} – {nickname}...\")\n",
    "all_x_foreground, all_x_background = agrupar_tensores(f\"{dataset_path}{dir_class}\")\n",
    "\n",
    "mean_dist_classe_classe, mean_dist_classe_not_classe, std_classe_classe, std_classe_not_classe = calcular_distancias_otimizado2(all_x_foreground.to(device), all_x_background.to(device), batch_size=4096)\n",
    "\n",
    "print(f\"Distância média {nickname}_{nickname}: {mean_dist_classe_classe}, {nickname}_not_{nickname}: {mean_dist_classe_not_classe}\")\n",
    "print(f\"Desvio padrão {nickname}_{nickname}: {std_classe_classe}, {nickname}_not_{nickname}: {std_classe_not_classe}\")\n",
    "\n",
    "results.append({\n",
    "    \"class\": nickname,\n",
    "    #\"all_foreground\": all_x_foreground,\n",
    "    #\"all_background\": all_x_background,\n",
    "    \"mean_dist_classe_classe\": mean_dist_classe_classe,\n",
    "    \"mean_dist_classe_not_classe\": mean_dist_classe_not_classe,\n",
    "    \"std_classe_classe\": std_classe_classe,\n",
    "    \"std_classe_not_classe\": std_classe_not_classe\n",
    "})\n",
    "\n",
    "del all_x_foreground, all_x_background\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Salvar resultados em um arquivo txt\n",
    "with open(\"pca_soja_results-2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "729c126c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando classe TREPADEIRA – TRE...\n",
      "Foram encontrados 2320 imagens e 2320 labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2320/2320 [02:13<00:00, 17.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Foreground: torch.Size([38800, 1024]), Total Background: torch.Size([555120, 1024])\n",
      "Iniciando cálculo otimizado com batch size: 4096\n",
      "Usando dispositivo: cuda:0\n",
      "Calculando distâncias intra-classe para 38,800 vetores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intra-classe: 100%|██████████| 10/10 [00:00<00:00, 40.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando distâncias inter-classe para 38,800 vs 555,120 vetores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inter-classe: 100%|██████████| 10/10 [00:04<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distância média TRE_TRE: 5.787045478820801, TRE_not_TRE: 6.364039421081543\n",
      "Desvio padrão TRE_TRE: 0.7135447263717651, TRE_not_TRE: 1.0036296844482422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class_name, dir_class, nickname = classes[5]\n",
    "\n",
    "print(f\"Processando classe {class_name} – {nickname}...\")\n",
    "all_x_foreground, all_x_background = agrupar_tensores(f\"{dataset_path}{dir_class}\")\n",
    "\n",
    "mean_dist_classe_classe, mean_dist_classe_not_classe, std_classe_classe, std_classe_not_classe = calcular_distancias_otimizado2(all_x_foreground.to(device), all_x_background.to(device), batch_size=4096)\n",
    "\n",
    "print(f\"Distância média {nickname}_{nickname}: {mean_dist_classe_classe}, {nickname}_not_{nickname}: {mean_dist_classe_not_classe}\")\n",
    "print(f\"Desvio padrão {nickname}_{nickname}: {std_classe_classe}, {nickname}_not_{nickname}: {std_classe_not_classe}\")\n",
    "\n",
    "results.append({\n",
    "    \"class\": nickname,\n",
    "    #\"all_foreground\": all_x_foreground,\n",
    "    #\"all_background\": all_x_background,\n",
    "    \"mean_dist_classe_classe\": mean_dist_classe_classe,\n",
    "    \"mean_dist_classe_not_classe\": mean_dist_classe_not_classe,\n",
    "    \"std_classe_classe\": std_classe_classe,\n",
    "    \"std_classe_not_classe\": std_classe_not_classe\n",
    "})\n",
    "\n",
    "del all_x_foreground, all_x_background\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Salvar resultados em um arquivo txt\n",
    "with open(\"pca_soja_results-2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28a3b6d",
   "metadata": {},
   "source": [
    "### Experimento 2: Foreground sera a mask das imagens da classe e Background sera a mask das imagens das outras classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc40e72f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-dino2 (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
