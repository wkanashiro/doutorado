{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ba60e5",
   "metadata": {},
   "source": [
    "# Roteiro para treinamento do DINOv3\n",
    "\n",
    "Inicialmente será realizado um treinamento com uma pequena porção do dataset, contendo alguns recortes de ortofotos. Caso esse treino dê certo, estenderemos para o dataset maior.\n",
    "\n",
    "## Objetivos\n",
    "* Verificar se o DINOv3 é capaz de aprender o contexto de soja\n",
    "\n",
    "## Objetivos específicos\n",
    "* Criar um modelo especialista em imagens de plantação de soja sem anotações\n",
    "* Criar uma representação visual (via PCA ou foreground segmentation), usando o modelo aprendido no treino\n",
    "\n",
    "## Etapas:\n",
    "**1) Organização do dataset**\n",
    "- Objetivo: converter o dataset no formato ImageNet\n",
    "- Formato esperado pelo DINO:\n",
    "\n",
    "        dataset_soja_dinov3/\n",
    "        ├── train/\n",
    "        │   └── soja/ \n",
    "        │       ├── soja_train_000001.jpg\n",
    "        │       ├── soja_train_000002.jpg\n",
    "        │       └── ...\n",
    "        ├── val/\n",
    "        │   └── soja/\n",
    "        │       ├── soja_val_000001.jpg\n",
    "        │       └── ...\n",
    "        └── extra/ -> Metadados\n",
    "            ├── class-ids-TRAIN.npy\n",
    "            ├── class-names-TRAIN.npy\n",
    "            └── ...\n",
    "\n",
    "**2. Organização do ambiente**\n",
    "- Verificar dependências específicas do DINO\n",
    "- Avaliar compatibilidade da GPU\n",
    "\n",
    "**3) Treinamento**\n",
    "- Ajustar o arquivo `yaml` para o treino\n",
    "- Iniciar o treinamento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd82b4f",
   "metadata": {},
   "source": [
    "### 1) Organização do dataset\n",
    "- Objetivo: converter o dataset no formato ImageNet\n",
    "- Formato esperado pelo DINO:\n",
    "\n",
    "        dataset_soja_dinov3/\n",
    "        ├── train/\n",
    "        │   └── soja/ \n",
    "        │       ├── soja_train_000001.jpg\n",
    "        │       ├── soja_train_000002.jpg\n",
    "        │       └── ...\n",
    "        ├── val/\n",
    "        │   └── soja/\n",
    "        │       ├── soja_val_000001.jpg\n",
    "        │       └── ...\n",
    "        └── extra/ -> Metadados\n",
    "            ├── class-ids-TRAIN.npy\n",
    "            ├── class-names-TRAIN.npy\n",
    "            └── ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2523f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0967ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organizar_dataset(source_dir, target_dir, split_ratio=0.8):\n",
    "    source_path = Path(source_dir)\n",
    "    target_path = Path(target_dir)\n",
    "    \n",
    "    train_dir = target_path / 'train' / 'soja'\n",
    "    val_dir = target_path / 'val' / 'soja'\n",
    "    \n",
    "    train_dir.mkdir(parents=True, exist_ok=True)\n",
    "    val_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']\n",
    "    all_images = []\n",
    "    \n",
    "    for ext in image_extensions:\n",
    "        all_images.extend(source_path.glob(ext))\n",
    "    \n",
    "    print(f\"📊 Total de imagens encontradas: {len(all_images)}\")\n",
    "    \n",
    "    random.shuffle(all_images)\n",
    "    split_index = int(len(all_images) * split_ratio)\n",
    "    train_images = all_images[:split_index]\n",
    "    val_images = all_images[split_index:]\n",
    "\n",
    "    for i, img in enumerate(train_images):\n",
    "        new_name = f\"soja_train_{i:06d}{img.suffix}\"\n",
    "        shutil.copy2(img, train_dir / new_name)\n",
    "\n",
    "    for i, img in enumerate(val_images):\n",
    "        new_name = f\"soja_val_{i:06d}{img.suffix}\"\n",
    "        shutil.copy2(img, val_dir / new_name)\n",
    "        \n",
    "    print(f\"✅ Dataset organizado:\")\n",
    "    print(f\"  📂 Treino: {len(train_images)} imagens\")\n",
    "    print(f\"  📂 Validação: {len(val_images)} imagens\")\n",
    "    print(f\"  📍 Localização: {target_path}\")\n",
    "    \n",
    "def create_metadata_files(dataset_path):\n",
    "    \n",
    "    # Criar diretório 'extra' para arquivos de metadados\n",
    "    extra_dir = dataset_path / 'extra'\n",
    "    extra_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Listar imagens de treino\n",
    "    train_images = list((dataset_path / \"train\" / \"soja\").glob(\"*\"))\n",
    "    print(f\"📊 Encontradas {len(train_images)} imagens de treino\")\n",
    "    \n",
    "    # 🔧 SOLUÇÃO: Usar dtype estruturado memory-mappable\n",
    "    # Definir dtype que suporta memory-mapping\n",
    "    max_path_length = max(len(f\"train/soja/{img.name}\") for img in train_images) + 10\n",
    "    \n",
    "    dtype_entries = np.dtype([\n",
    "        ('path', f'U{max_path_length}'),  # String Unicode de tamanho fixo\n",
    "        ('class_id', np.int32)            # Inteiro 32-bit\n",
    "    ])\n",
    "    \n",
    "    print(f\"📋 Usando dtype: {dtype_entries}\")\n",
    "    print(f\"📏 Tamanho máximo de path: {max_path_length}\")\n",
    "    \n",
    "    # Criar array estruturado\n",
    "    train_entries = np.empty(len(train_images), dtype=dtype_entries)\n",
    "    \n",
    "    for i, img in enumerate(train_images):\n",
    "        rel_path = f\"train/soja/{img.name}\"\n",
    "        train_entries[i] = (rel_path, 0)  # (path, class_id)\n",
    "    \n",
    "    # Salvar como .npy\n",
    "    entries_file = extra_dir / \"entries-TRAIN.npy\"\n",
    "    np.save(entries_file, train_entries)\n",
    "    print(f\"✅ Criado {entries_file}\")\n",
    "    print(f\"   📊 Shape: {train_entries.shape}\")\n",
    "    print(f\"   📊 Dtype: {train_entries.dtype}\")\n",
    "    \n",
    "    # 🔧 TESTE CRÍTICO: Verificar memory-mapping\n",
    "    try:\n",
    "        test_mmap = np.load(entries_file, mmap_mode=\"r\")\n",
    "        print(f\"✅ Memory-mapping TEST: SUCESSO!\")\n",
    "        print(f\"   📋 Primeira entrada: {test_mmap[0]}\")\n",
    "        print(f\"   📋 Tipos: path={type(test_mmap[0]['path'])}, class_id={type(test_mmap[0]['class_id'])}\")\n",
    "        \n",
    "        # Verificar se consegue acessar path e class_id\n",
    "        first_path = test_mmap[0]['path']\n",
    "        first_class = test_mmap[0]['class_id']\n",
    "        print(f\"   📋 Path: '{first_path}', Class: {first_class}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERRO no memory-mapping: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Criar arquivos auxiliares também\n",
    "    class_ids = np.zeros(len(train_images), dtype=np.int32)\n",
    "    class_names = np.array(['soja'] * len(train_images), dtype='U10')  # String fixa\n",
    "    \n",
    "    np.save(extra_dir / \"class-ids-TRAIN.npy\", class_ids)\n",
    "    np.save(extra_dir / \"class-names-TRAIN.npy\", class_names)\n",
    "    \n",
    "    # Processar VAL se existir\n",
    "    val_dir = dataset_path / \"val\" / \"soja\"\n",
    "    if val_dir.exists():\n",
    "        val_images = list(val_dir.glob(\"*\"))\n",
    "        print(f\"📊 Encontradas {len(val_images)} imagens de validação\")\n",
    "        \n",
    "        # VAL entries\n",
    "        val_entries = np.empty(len(val_images), dtype=dtype_entries)\n",
    "        for i, img in enumerate(val_images):\n",
    "            rel_path = f\"val/soja/{img.name}\"\n",
    "            val_entries[i] = (rel_path, 0)\n",
    "        \n",
    "        val_entries_file = extra_dir / \"entries-VAL.npy\"\n",
    "        np.save(val_entries_file, val_entries)\n",
    "        \n",
    "        # Testar VAL memory-mapping também\n",
    "        try:\n",
    "            test_val_mmap = np.load(val_entries_file, mmap_mode=\"r\")\n",
    "            print(f\"✅ VAL Memory-mapping TEST: SUCESSO!\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ ERRO VAL memory-mapping: {e}\")\n",
    "            return False\n",
    "        \n",
    "        # VAL auxiliares\n",
    "        val_class_ids = np.zeros(len(val_images), dtype=np.int32)\n",
    "        val_class_names = np.array(['soja'] * len(val_images), dtype='U10')\n",
    "        \n",
    "        np.save(extra_dir / \"class-ids-VAL.npy\", val_class_ids)\n",
    "        np.save(extra_dir / \"class-names-VAL.npy\", val_class_names)\n",
    "        \n",
    "        print(f\"✅ Todos os arquivos VAL criados\")\n",
    "    \n",
    "    print(f\"\\n🎉 TODOS OS ARQUIVOS CRIADOS COM SUCESSO!\")\n",
    "    print(f\"📁 Diretório: {extra_dir}\")\n",
    "    \n",
    "    # Listar arquivos criados\n",
    "    print(\"📋 Arquivos criados:\")\n",
    "    for file in extra_dir.glob(\"*.npy\"):\n",
    "        file_size = file.stat().st_size / 1024  # KB\n",
    "        print(f\"   📄 {file.name}: {file_size:.1f} KB\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1744db3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Total de imagens encontradas: 764\n",
      "✅ Dataset organizado:\n",
      "  📂 Treino: 611 imagens\n",
      "  📂 Validação: 153 imagens\n",
      "  📍 Localização: /home/lades/computer_vision/wesley/dino-soja/dataset/teste-organizado-dinov3\n",
      "📊 Encontradas 611 imagens de treino\n",
      "✅ Criado entries-TRAIN.npy: (611, 2)\n",
      "✅ Teste carregamento: OK, shape=(611, 2)\n",
      "📋 Primeira entrada: ['train/soja/soja_train_000367.jpg' 0]\n",
      "📋 Tipo primeira entrada: <class 'str'>, <class 'int'>\n",
      "✅ Criados todos os arquivos auxiliares\n",
      "📊 Encontradas 153 imagens de validação\n",
      "✅ Criados arquivos VAL também\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"/home/lades/computer_vision/wesley/dataset/daninhas_multiclasse2/teste-dino/\"\n",
    "target_dir = \"/home/lades/computer_vision/wesley/dino-soja/dataset/teste-organizado-dinov3/\"\n",
    "\n",
    "organizar_dataset(source_dir, target_dir, split_ratio=0.8)\n",
    "\n",
    "create_metadata_files(Path(target_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "722a9690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Encontradas 611 imagens de treino\n",
      "📋 Usando dtype: [('path', '<U42'), ('class_id', '<i4')]\n",
      "📏 Tamanho máximo de path: 42\n",
      "✅ Criado /home/lades/computer_vision/wesley/dino-soja/dataset/teste-organizado-dinov3/extra/entries-TRAIN.npy\n",
      "   📊 Shape: (611,)\n",
      "   📊 Dtype: [('path', '<U42'), ('class_id', '<i4')]\n",
      "✅ Memory-mapping TEST: SUCESSO!\n",
      "   📋 Primeira entrada: ('train/soja/soja_train_000367.jpg', 0)\n",
      "   📋 Tipos: path=<class 'numpy.str_'>, class_id=<class 'numpy.int32'>\n",
      "   📋 Path: 'train/soja/soja_train_000367.jpg', Class: 0\n",
      "📊 Encontradas 153 imagens de validação\n",
      "✅ VAL Memory-mapping TEST: SUCESSO!\n",
      "✅ Todos os arquivos VAL criados\n",
      "\n",
      "🎉 TODOS OS ARQUIVOS CRIADOS COM SUCESSO!\n",
      "📁 Diretório: /home/lades/computer_vision/wesley/dino-soja/dataset/teste-organizado-dinov3/extra\n",
      "📋 Arquivos criados:\n",
      "   📄 class-ids-TRAIN.npy: 2.5 KB\n",
      "   📄 class-ids-VAL.npy: 0.7 KB\n",
      "   📄 class-names-TRAIN.npy: 24.0 KB\n",
      "   📄 class-names-VAL.npy: 6.1 KB\n",
      "   📄 entries-VAL.npy: 25.8 KB\n",
      "   📄 entries-TRAIN.npy: 102.8 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_metadata_files(Path(target_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-dino (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
